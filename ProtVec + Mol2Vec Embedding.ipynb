{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e0b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install tensorflow\n",
    "!pip install lifelines\n",
    "# Install Mol2vec\n",
    "!pip install git+https://github.com/samoturk/mol2vec\n",
    "!pip install pyfaidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81be16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3dd181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all needed packages\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import math as math\n",
    "import numpy as np\n",
    "from math import exp\n",
    "# import argparse\n",
    "import json,csv, pickle\n",
    "import itertools,collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML packages\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from joblib import Parallel, delayed\n",
    "# import multiprocessing\n",
    "import xgboost as xgb\n",
    "\n",
    "# normalization packages\n",
    "from sklearn.preprocessing import MinMaxScaler, minmax_scale\n",
    "import scipy\n",
    "from scipy import *\n",
    "\n",
    "# DL Keras\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "from keras.layers import Embedding, Input, Reshape, Dense, concatenate\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "# for protein embedding\n",
    "import biovec\n",
    "\n",
    "# for drugs embedding\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import deepchem as dc\n",
    "# from deepchem.feat import Featurizer\n",
    "# from deepchem.models.optimizers import ExponentialDecay, Adam\n",
    "# from deepchem.models.seqtoseq import AspuruGuzikAutoEncoder\n",
    "# from deepchem.metrics import to_one_hot\n",
    "# from deepchem.models.graph_models import GraphConvModel,L2Loss,Dense,Reshape,Dropout \n",
    "\n",
    "# Import my files\n",
    "from training_functions import *\n",
    "from pathScores_functions import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bafea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ea16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "all_DTA_info = pd.read_csv('/DAVIS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cac2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import trained model\n",
    "pv = biovec.models.load_protvec('/home/amit/BindingAffinity/Trained_models/swissprot-reviewed-protvec.model')\n",
    "\n",
    "Embed = {}\n",
    "seqEmbed = []\n",
    "sumEmbed = []\n",
    "avgEmbed = []\n",
    "allEmbed = []\n",
    "\n",
    "all_DT_df = pd.read_csv(\"/DAVIS.csv\")\n",
    "all_DT_df['Seq'] = all_DT_df['Seq'].astype(str)\n",
    "all_DT_df = all_DT_df.dropna()\n",
    "\n",
    "# Remove rows with missing values in the 'Seq' column\n",
    "all_DT_df = all_DT_df.dropna(subset=['Seq'])\n",
    "all_DT_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "for i in range(all_DT_df.shape[0]):\n",
    "    embedding = pv.to_vecs(all_DT_df['Seq'][i])\n",
    "    # Dictionary to get embedding by target ID\n",
    "    Embed[all_DT_df['pdbID'][i]] = embedding\n",
    "    \n",
    "    allem = list(itertools.chain(embedding[0],embedding[1],embedding[2]))\n",
    "    #concatenate 3d\n",
    "    allEmbed.append(allem)\n",
    "    #list of embedding 3D\n",
    "    seqEmbed.append(embedding)\n",
    "    \n",
    "    # 1D embedding by taking sum of 3 ists\n",
    "    sumE = embedding[0]+embedding[1]+embedding[2]\n",
    "    sumEmbed.append(sumE)\n",
    "    \n",
    "    #1D embedding by taking the average\n",
    "    #avgEmbed.append(sumE/3)\n",
    "    \n",
    "#avgEmbed = np.array(avgEmbed)\n",
    "sumEmbed = np.array(sumEmbed)\n",
    "sumEmbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6708f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_pdb_Sm = list(all_DT_df['SMILES'])\n",
    "df = pd.DataFrame({'smiles': dr_pdb_Sm})\n",
    "\n",
    "df = df.dropna(subset=['smiles'])\n",
    "df['mol'] = df['smiles'].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "\n",
    "df['sentence'] = df.apply(lambda x: MolSentence(mol2alt_sentence(x['mol'], 1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the dataframe has valid smiles or not\n",
    "\n",
    "def validate_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df['valid_smiles'] = df['smiles'].apply(validate_smiles)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    print(row['smiles'], row['valid_smiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Mol2Vec pretrained model\n",
    "model = word2vec.Word2Vec.load('Trained_models/model_300dim.pkl')\n",
    "df['mol2vec'] = [DfVec(x) for x in sentences2vec(df['sentence'], model, unseen='UNK')]\n",
    "pdb_sm_EMBED = np.array([x.vec for x in df['mol2vec']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf034ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/data/amit/Mol2Vec_EMB_BindingDB_excluding_bad_conformers.npy', pdb_sm_EMBED)\n",
    "pdb_sm_EMBED = np.load('/data/amit/Mol2Vec_EMB_BindingDB_excluding_bad_conformers.npy',allow_pickle=True)\n",
    "pdb_sm_unique = np.array(list(ligand_un_df['SMILES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'smiles': pdb_sm_unique})\n",
    "df1 = df1.dropna(subset=['smiles'])\n",
    "#Transforming SMILES to MOL\n",
    "df1['mol'] = df1['smiles'].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "\n",
    "#Constructing sentences\n",
    "df1['sentence'] = df1.apply(lambda x: MolSentence(mol2alt_sentence(x['mol'], 1)), axis=1)\n",
    "\n",
    "#Extracting embeddings to a numpy.array\n",
    "df1['mol2vec'] = [DfVec(x) for x in sentences2vec(df1['sentence'], model, unseen='UNK')]\n",
    "pdb_sm_EMBED_u = np.array([x.vec for x in df1['mol2vec']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c5f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Sequence Embeddings and SMILES Embeddings into file\n",
    "Pr_EMBED_df = pd.DataFrame.from_dict(sumEmbed)\n",
    "Pr_EMBED_df.to_csv('/EMBED/Pr_ProtVec_EMBED.txt',sep=' ',index=None,header=None)\n",
    "\n",
    "pdb_EMBED_df = pd.DataFrame.from_dict(pdb_sm_EMBED)\n",
    "pdb_EMBED_df.to_csv('/EMBED/Dr_Mol2Vec_EMBED.txt',sep=' ',index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5175a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
