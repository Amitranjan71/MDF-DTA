{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497532a4",
   "metadata": {},
   "source": [
    "# EGNN Molecular Represitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d05b6",
   "metadata": {},
   "source": [
    "**Licenses**\n",
    "\n",
    "Copyright (c) DP Technology.\n",
    "\n",
    "This source code is licensed under the MIT license found in the\n",
    "LICENSE file in the root directory of this source tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a811f1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lmdb\n",
      "  Downloading lmdb-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.5/298.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lmdb\n",
      "Successfully installed lmdb-1.4.1\n",
      "Requirement already satisfied: rdkit in /home/amit/anaconda3/lib/python3.9/site-packages (2023.3.1)\n",
      "Requirement already satisfied: Pillow in /home/amit/anaconda3/lib/python3.9/site-packages (from rdkit) (9.2.0)\n",
      "Requirement already satisfied: numpy in /home/amit/anaconda3/lib/python3.9/site-packages (from rdkit) (1.23.5)\n",
      "Collecting unicore==0.0.1+cu113torch1.12.1\n",
      "  Downloading https://github.com/dptech-corp/Uni-Core/releases/download/0.0.1/unicore-0.0.1+cu113torch1.12.1-cp39-cp39-linux_x86_64.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/amit/anaconda3/lib/python3.9/site-packages (from unicore==0.0.1+cu113torch1.12.1) (1.8.1)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.11.0 in /home/amit/anaconda3/lib/python3.9/site-packages (from unicore==0.0.1+cu113torch1.12.1) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /home/amit/anaconda3/lib/python3.9/site-packages (from unicore==0.0.1+cu113torch1.12.1) (2.0.0)\n",
      "Collecting ml-collections\n",
      "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/amit/anaconda3/lib/python3.9/site-packages (from unicore==0.0.1+cu113torch1.12.1) (1.23.5)\n",
      "Requirement already satisfied: lmdb in /home/amit/anaconda3/lib/python3.9/site-packages (from unicore==0.0.1+cu113torch1.12.1) (1.4.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (8.5.0.96)\n",
      "Requirement already satisfied: filelock in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (3.6.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (4.3.0)\n",
      "Requirement already satisfied: networkx in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (2.8.4)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (11.7.4.91)\n",
      "Requirement already satisfied: jinja2 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (2.11.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (10.9.0.58)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (2.0.0)\n",
      "Requirement already satisfied: sympy in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (1.10.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/amit/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (11.7.101)\n",
      "Requirement already satisfied: wheel in /home/amit/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /home/amit/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (63.4.1)\n",
      "Requirement already satisfied: cmake in /home/amit/anaconda3/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/amit/anaconda3/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (16.0.3)\n",
      "Requirement already satisfied: absl-py in /home/amit/anaconda3/lib/python3.9/site-packages (from ml-collections->unicore==0.0.1+cu113torch1.12.1) (1.4.0)\n",
      "Requirement already satisfied: PyYAML in /home/amit/anaconda3/lib/python3.9/site-packages (from ml-collections->unicore==0.0.1+cu113torch1.12.1) (6.0)\n",
      "Requirement already satisfied: six in /home/amit/anaconda3/lib/python3.9/site-packages (from ml-collections->unicore==0.0.1+cu113torch1.12.1) (1.16.0)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: packaging in /home/amit/anaconda3/lib/python3.9/site-packages (from tensorboardX->unicore==0.0.1+cu113torch1.12.1) (21.3)\n",
      "Collecting protobuf<4,>=3.8.0\n",
      "  Using cached protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/amit/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (2.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/amit/anaconda3/lib/python3.9/site-packages (from packaging->tensorboardX->unicore==0.0.1+cu113torch1.12.1) (3.0.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/amit/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.11.0->unicore==0.0.1+cu113torch1.12.1) (1.2.1)\n",
      "Building wheels for collected packages: ml-collections\n",
      "  Building wheel for ml-collections (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=1f17d187360d0dfc4941a0411b9b8268633a999f4d1d1057340d7af81dfef97c\n",
      "  Stored in directory: /home/amit/.cache/pip/wheels/fd/c2/0d/5d94d95e5875ea17b85a9f1f99b8dd2e50517137c8042c6468\n",
      "Successfully built ml-collections\n",
      "Installing collected packages: tokenizers, protobuf, contextlib2, tensorboardX, ml-collections, unicore\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.0\n",
      "    Uninstalling protobuf-4.23.0:\n",
      "      Successfully uninstalled protobuf-4.23.0\n",
      "Successfully installed contextlib2-21.6.0 ml-collections-0.1.1 protobuf-3.20.3 tensorboardX-2.6 tokenizers-0.13.3 unicore-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lmdb\n",
    "!pip install rdkit\n",
    "!pip install https://github.com/dptech-corp/Uni-Core/releases/download/0.0.1/unicore-0.0.1+cu113torch1.12.1-cp39-cp39-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65cf6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lmdb\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4277b7f",
   "metadata": {},
   "source": [
    "### Your SMILES list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3baed7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "smi_list = [\n",
    "'C1C2C(C3C(C(O2)O)OC(=O)C4=CC(=C(C(=C4C5=C(C(=C(C=C5C(=O)O3)O)O)O)O)O)O)OC(=O)C6=CC(=C(C(=C6C7=C(C(=C8C9=C7C(=O)OC2=C(C(=C(C3=C(C(=C(C=C3C1=O)O)O)O)C(=C92)C(=O)O8)O)O)O)O)O)O)O',\n",
    "'C1C2C(C3C(C(O2)OC(=O)C4=CC(=C(C(=C4)OC5=C(C(=C(C6=C5C(=O)OC7C(COC(=O)C8=CC(=C(C(=C86)O)O)O)OC(C9C7OC(=O)C2=CC(=C(C(=C2C2=C(C(=C(C=C2C(=O)O9)O)O)O)O)O)O)OC(=O)C2=CC(=C(C(=C2)OC2=C(C(=C(C4=C2C(=O)OC2C(COC(=O)C5=CC(=C(C(=C54)O)O)O)OC(C4C2OC(=O)C2=CC(=C(C(=C2C2=C(C(=C(C=C2C(=O)O4)O)O)O)O)O)O)OC(=O)C2=CC(=C(C(=C2)OC2=C(C(=C(C4=C2C(=O)OC2C(COC(=O)C5=CC(=C(C(=C54)O)O)O)OC(C4C2OC(=O)C2=CC(=C(C(=C2C2=C(C(=C(C=C2C(=O)O4)O)O)O)O)O)O)OC(=O)C2=CC(=C(C(=C2)O)O)O)O)O)O)O)O)O)O)O)O)O)O)O)O)O)O)OC(=O)C2=CC(=C(C(=C2C2=C(C(=C(C=C2C(=O)O3)O)O)O)O)O)O)OC(=O)C2=CC(=C(C(=C2C2=C(C(=C(C=C2C(=O)O1)O)O)O)O)O)O',\n",
    "'C1=CC2=C(C=CN=C2)C(=C1)S(=O)(=O)NCCNCCC(=O)NC(CO)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)O'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51d04bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2065"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('/data/amit/DAVIS/KIBA_with_Emb/unique_smiles.csv')\n",
    "\n",
    "# Extract the SMILES column as a list\n",
    "smile_list = df['Drug'].tolist()\n",
    "\n",
    "len(smile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "025dcb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"/data/amit/DAVIS/ligands_can_kiba.txt\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f9f6e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2111"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update the bad conformer ID\n",
    "\n",
    "key_to_update = \"CHEMBL436718\"  # Key whose value you want to change\n",
    "new_value = \"N=C(N)NCCC[C@H](NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@H](CO)NC(=O)CCNCCNS(=O)(=O)c1cccc2cnccc12)C(=O)O\"  # New value to assign to the key\n",
    "\n",
    "updated_data[key_to_update] = new_value  # Update the value associated with the key\n",
    "\n",
    "# Return the updated dictionary (optional)\n",
    "#updated_data = data\n",
    "\n",
    "    \n",
    "smile_list = list(updated_data.values())\n",
    "len(smile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08509ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1=CC2=C(C=CN=C2)C(=C1)S(=O)(=O)NCCNCCC(=O)NC(CO)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)O'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smile_list[1864]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bea5f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6ae04d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b38950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d064627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f14d924f",
   "metadata": {},
   "source": [
    "### Generate conformations from SMILES and save to .lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d20ade1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smi2coords(smi, seed):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    mol = AllChem.AddHs(mol)\n",
    "    atoms = [atom.GetSymbol() for atom in mol.GetAtoms()]\n",
    "    coordinate_list = []\n",
    "    res = AllChem.EmbedMolecule(mol, randomSeed=seed)\n",
    "    if res == 0:\n",
    "        try:\n",
    "            AllChem.MMFFOptimizeMolecule(mol)\n",
    "        except:\n",
    "            pass\n",
    "        coordinates = mol.GetConformer().GetPositions()\n",
    "    elif res == -1:\n",
    "        mol_tmp = Chem.MolFromSmiles(smi)\n",
    "        AllChem.EmbedMolecule(mol_tmp, maxAttempts=5000, randomSeed=seed)\n",
    "        mol_tmp = AllChem.AddHs(mol_tmp, addCoords=True)\n",
    "        try:\n",
    "            AllChem.MMFFOptimizeMolecule(mol_tmp)\n",
    "        except:\n",
    "            pass\n",
    "        coordinates = mol_tmp.GetConformer().GetPositions()\n",
    "    assert len(atoms) == len(coordinates), \"coordinates shape is not align with {}\".format(smi)\n",
    "    coordinate_list.append(coordinates.astype(np.float32))\n",
    "    return pickle.dumps({'atoms': atoms, 'coordinates': coordinate_list, 'smi': smi}, protocol=-1)\n",
    "\n",
    "def write_lmdb(smiles_list, job_name, seed=42, outpath='./results'):\n",
    "    os.makedirs(outpath, exist_ok=True)\n",
    "    output_name = os.path.join(outpath,'{}.lmdb'.format(job_name))\n",
    "    try:\n",
    "        os.remove(output_name)\n",
    "    except:\n",
    "        pass\n",
    "    env_new = lmdb.open(\n",
    "        output_name,\n",
    "        subdir=False,\n",
    "        readonly=False,\n",
    "        lock=False,\n",
    "        readahead=False,\n",
    "        meminit=False,\n",
    "        max_readers=1,\n",
    "        map_size=int(100e9),\n",
    "    )\n",
    "    txn_write = env_new.begin(write=True)\n",
    "    for i, smiles in tqdm(enumerate(smiles_list)):\n",
    "        inner_output = smi2coords(smiles, seed=seed)\n",
    "        txn_write.put(f\"{i}\".encode(\"ascii\"), inner_output)\n",
    "    txn_write.commit()\n",
    "    env_new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10799302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "793dfda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1=CC2=C(C=CN=C2)C(=C1)S(=O)(=O)NCCNCCC(=O)NC(CO)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)O'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smile_list[1864]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255298b",
   "metadata": {},
   "source": [
    "C1=CC2=C(C=CN=C2)C(=C1)S(=O(=O)NCCNCCC(=O)NC(CO)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)NC(CCCN=C(N)N)C(=O)O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34f689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83e3735a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smile for ID 1799: C1C2C(C3C(C(O2)O)OC(=O)C4=CC(=C(C(=C4C5=C(C(=C(C=C5C(=O)O3)O)O)O)O)O)O)OC(=O)C6=CC(=C(C(=C6C7=C(C(=C8C9=C7C(=O)OC2=C(C(=C(C3=C(C(=C(C=C3C1=O)O)O)O)C(=C92)C(=O)O8)O)O)O)O)O)O)O\n"
     ]
    }
   ],
   "source": [
    "print(\"Smile for ID 1799:\", smile_list[1799])\n",
    "#print(\"Smile for ID 1367:\", smile_list[1367])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79982b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming your list is named 'my_list'\n",
    "smile_list2 = smile_list[1864:]\n",
    "#1799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c04185f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:06:21] Molecule does not have explicit Hs. Consider calling AddHs()\n"
     ]
    }
   ],
   "source": [
    "smiles = 'N=C(N)NCCC[C@H](NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@H](CO)NC(=O)CCNCCNS(=O)(=O)c1cccc2cnccc12)C(=O)O'\n",
    "inner_output = smi2coords(smiles, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "918c13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_list3 = smile_list2[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534db63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73bb590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_list4 = smile_list3[24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae0f60a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1693it [02:47, 10.10it/s][15:10:19] Molecule does not have explicit Hs. Consider calling AddHs()\n",
      "[15:10:20] Molecule does not have explicit Hs. Consider calling AddHs()\n",
      "1699it [02:50,  9.97it/s][15:10:22] Molecule does not have explicit Hs. Consider calling AddHs()\n",
      "1819it [03:17,  9.23it/s][15:10:49] Molecule does not have explicit Hs. Consider calling AddHs()\n",
      "1837it [03:26,  8.87it/s][15:10:57] Molecule does not have explicit Hs. Consider calling AddHs()\n",
      "1843it [03:34,  8.61it/s][15:11:05] Molecule does not have explicit Hs. Consider calling AddHs()\n",
      "1861it [03:41,  8.41it/s][15:11:13] Molecule does not have explicit Hs. Consider calling AddHs()\n",
      "1873it [03:47,  8.24it/s][15:11:18] Molecule does not have explicit Hs. Consider calling AddHs()\n",
      "                         \r"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "job_name = 'get_mol_repr'   #custom name\n",
    "data_path = '/data/amit/results'  #data path\n",
    "weight_path='/home/amit/Uni-Mol/unimol/mol_pre_no_h_220816.pt'  #ckpt path\n",
    "only_polar=0  # no h\n",
    "dict_name='dict.txt'\n",
    "batch_size=16\n",
    "results_path=data_path   #save path\n",
    "write_lmdb(smile_list, job_name=job_name, seed=seed, outpath=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e426be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ca56e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee92064e",
   "metadata": {},
   "source": [
    "### Infer from ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "633dc09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fused_multi_tensor is not installed corrected\n",
      "fused_rounding is not installed corrected\n",
      "fused_layer_norm is not installed corrected\n",
      "fused_softmax is not installed corrected\n",
      "2023-06-15 15:12:05 | INFO | unimol.inference | loading model(s) from /home/amit/Uni-Mol/unimol/mol_pre_no_h_220816.pt\n",
      "2023-06-15 15:12:06 | INFO | unimol.tasks.unimol | dictionary: 30 types\n",
      "2023-06-15 15:12:09 | INFO | unimol.inference | Namespace(no_progress_bar=False, log_interval=50, log_format='simple', tensorboard_logdir='', seed=1, cpu=False, fp16=False, bf16=False, bf16_sr=False, allreduce_fp32_grad=False, fp16_no_flatten_grads=False, fp16_init_scale=4, fp16_scale_window=256, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir='../unimol', empty_cache_freq=0, all_gather_list_size=16384, suppress_crashes=False, profile=False, ema_decay=-1.0, loss='unimol_infer', optimizer='adam', lr_scheduler='fixed', task='unimol', num_workers=8, skip_invalid_size_inputs_valid_test=False, batch_size=16, required_batch_size_multiple=8, data_buffer_size=10, train_subset='train', valid_subset='get_mol_repr', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, batch_size_valid=16, max_valid_steps=None, curriculum=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, nprocs_per_node=1, path='/home/amit/Uni-Mol/unimol/mol_pre_no_h_220816.pt', quiet=False, model_overrides='{}', results_path='/data/amit/results', arch='unimol_base', mode='infer', data='/data/amit/results', mask_prob=0.15, leave_unmasked_prob=1.0, random_token_prob=0.0, noise_type='uniform', noise=1.0, remove_hydrogen=True, remove_polar_hydrogen=False, max_atoms=256, dict_name='dict.txt', only_polar=0, adam_betas='(0.9, 0.999)', adam_eps=1e-08, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, no_seed_provided=False, encoder_layers=15, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_attention_heads=64, dropout=0.1, emb_dropout=0.1, attention_dropout=0.1, activation_dropout=0.0, pooler_dropout=0.0, max_seq_len=512, activation_fn='gelu', pooler_activation_fn='tanh', post_ln=False, masked_token_loss=-1.0, masked_coord_loss=-1.0, masked_dist_loss=-1.0, x_norm_loss=-1.0, delta_pair_repr_norm_loss=-1.0, distributed_num_procs=1)\n",
      "2023-06-15 15:12:09 | INFO | unicore.tasks.unicore_task | get EpochBatchIterator for epoch 1\n",
      "2023-06-15 15:12:12 | INFO | unicore.logging.progress_bar | valid on 'get_mol_repr' subset:     51 / 132 \n",
      "2023-06-15 15:12:14 | INFO | unicore.logging.progress_bar | valid on 'get_mol_repr' subset:    101 / 132 \n",
      "2023-06-15 15:12:16 | INFO | unimol.inference | Done inference! \n"
     ]
    }
   ],
   "source": [
    "# NOTE: Currently, the inference is only supported to run on a single GPU. You can add CUDA_VISIBLE_DEVICES=\"0\" before the command.\n",
    "!cp ../example_data/molecule/$dict_name $data_path\n",
    "#!TORCH_USE_RTLD_GLOBAL=1\n",
    "!CUDA_VISIBLE_DEVICES=\"0\" python ../unimol/infer.py --user-dir ../unimol $data_path --valid-subset $job_name \\\n",
    "       --results-path $results_path \\\n",
    "       --num-workers 8 --ddp-backend=c10d --batch-size $batch_size \\\n",
    "       --task unimol --loss unimol_infer --arch unimol_base \\\n",
    "       --path $weight_path \\\n",
    "       --fp16-init-scale 4 --fp16-scale-window 256 \\\n",
    "       --only-polar $only_polar --dict-name $dict_name \\\n",
    "       --log-interval 50 --log-format simple --random-token-prob 0 --leave-unmasked-prob 1.0 --mode infer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8011b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Currently, the inference is only supported to run on a single GPU. You can add CUDA_VISIBLE_DEVICES=\"0\" before the command.\n",
    "!cp ../example_data/molecule/$dict_name $data_path\n",
    "#!TORCH_USE_RTLD_GLOBAL=1\n",
    "!CUDA_VISIBLE_DEVICES=\"2\" python ../unimol/infer.py --user-dir ../unimol $data_path --valid-subset $job_name \\\n",
    "       --results-path $results_path \\\n",
    "       --num-workers 8 --ddp-backend=c10d --batch-size $batch_size \\\n",
    "       --task unimol --loss unimol_infer --arch unimol_base \\\n",
    "       --path $weight_path \\\n",
    "       --fp16 --fp16-init-scale 4 --fp16-scale-window 256 \\\n",
    "       --only-polar $only_polar --dict-name $dict_name \\\n",
    "       --log-interval 50 --log-format simple --random-token-prob 0 --leave-unmasked-prob 1.0 --mode infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2142ee",
   "metadata": {},
   "source": [
    "### Read .pkl and save results to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_results(predict_path, results_path):\n",
    "    predict = pd.read_pickle(predict_path)\n",
    "    smi_list, mol_repr_list, pair_repr_list = [], [], []\n",
    "    for batch in predict:\n",
    "        sz = batch[\"bsz\"]\n",
    "        for i in range(sz):\n",
    "            smi_list.append(batch[\"smi_name\"][i])\n",
    "            mol_repr_list.append(batch[\"mol_repr_cls\"][i])\n",
    "            pair_repr_list.append(batch[\"pair_repr\"][i])\n",
    "    predict_df = pd.DataFrame({\"SMILES\": smi_list, \"mol_repr\": mol_repr_list, \"pair_repr\": pair_repr_list})\n",
    "    print(predict_df.head(1),predict_df.info())\n",
    "    predict_df.to_csv(results_path+'/mol_repr.csv',index=False)\n",
    "\n",
    "pkl_path = glob.glob(f'{results_path}/*_{job_name}.out.pkl')[0]\n",
    "get_csv_results(pkl_path, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0924a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1bf9561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save the embeddings in a .npy file\n",
    "def get_mol_repr(predict_path, result_path):\n",
    "    predict = pd.read_pickle(predict_path)\n",
    "    mol_repr_list = []\n",
    "    for batch in predict:\n",
    "        sz = batch[\"bsz\"]\n",
    "        for i in range(sz):\n",
    "            mol_repr_list.append(batch[\"mol_repr_cls\"][i])\n",
    "    mol_repr_arr = np.array(mol_repr_list)\n",
    "    np.save(f\"{result_path}/mol_repr_arr.npy\", mol_repr_arr)\n",
    "    \n",
    "pkl_path = glob.glob(f'{results_path}/*_{job_name}.out.pkl')[0]\n",
    "get_mol_repr(pkl_path, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2690b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2111, 512)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = np.load('/data/amit/results/mol_repr_arr.npy')\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36175032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
